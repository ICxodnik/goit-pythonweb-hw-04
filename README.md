## Завдання 1

Напишіть Python-скрипт, який буде читати всі файли у вказаній користувачем вихідній папці (source folder) і розподіляти їх по підпапках у директорії призначення (output folder) на основі розширення файлів. Скрипт повинен виконувати сортування асинхронно для більш ефективної обробки великої кількості файлів.



## Завдання 2

Напишіть Python-скрипт, який завантажує текст із заданої URL-адреси, аналізує частоту використання слів у тексті за допомогою парадигми MapReduce і візуалізує топ-слова з найвищою частотою використання у тексті.


![alt text](2/Screenshot%202025-03-17%20at%2005.49.43.png)

Так як в домашній роботі було вказано що треба використовувати потоки я додала нову реалізацію map_reduce_parallel (на потоках) та залишила стару реалізацію map_reduce_parallel_processes (на процесах).

### Результати вимірювань
Для вимірювання часу виконання я використала функцію `time.time()` і вимірювала час виконання кожної функції при різній кількості процесів та потоків.

![alt text](2/Screenshot%202025-03-18%20at%2017.12.27.png)

Як видно з графіків, використання процесів призводить до збільшення часу виконання. Я припускаю це через витрати на створення нових процесів та передачу даних між ними, що в даному випадку займає більше часу ніж використання потоків, навіть попри GIL.

Щоб перевиити це я тимчасова додала CPU-bound операцію в `map_reduce` щоб імітувати більш складні операції обчислення.
![alt text](2/Screenshot%202025-03-18%20at%2017.05.21.png)

Як видно зі скриншота вище, в такому випадку використання процесів більш ефективно. Також GIL не дозволяє отримати вигоду від використання потоків для CPU-bound операцій, як видно на скриншоті час виконання між 1 потоком та 4 потоками майже не змінився (навіть трохи збільшився).
